{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST, mnist, CIFAR10\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex1um/.local/lib/python3.11/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTargetTransform:\n",
    "    def __init__(self, num_classes=10):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __call__(self, target):\n",
    "        new_target = torch.zeros(self.num_classes, dtype=torch.float, device=device)\n",
    "        new_target[target] = 1\n",
    "        return new_target\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Lambda(lambda x: x.float().to(device))\n",
    "])\n",
    "\n",
    "# data_loader = DataLoader(dataset, batch_size=800, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# dataset = mnist.FashionMNIST(\"data\", download=True, train=True, transform=transform, target_transform=CustomTargetTransform())\n",
    "# dataset_target = mnist.FashionMNIST(\"data\", download=True, train=False, transform=transforms.PILToTensor())\n",
    "dataset = CIFAR10(\"data\", download=True, train=True, transform=transform, target_transform=CustomTargetTransform())\n",
    "dataset_target = CIFAR10(\"data\", download=True, train=False, transform=transform, target_transform=CustomTargetTransform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loader = DataLoader(dataset_target, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, batch_norm1, batch_norm2, inter_channels, kernel_size1, kernel_size2, stride1, stride2, padding1=1, padding2=1, in_size=28):\n",
    "        super().__init__()\n",
    "        block = [\n",
    "            nn.Conv2d(in_channels, inter_channels, kernel_size1, stride1, padding1),\n",
    "        ]\n",
    "        if batch_norm1:\n",
    "            block.append(nn.BatchNorm2d(inter_channels))\n",
    "        block.append(nn.ReLU())\n",
    "        block.append(nn.Conv2d(inter_channels, in_channels, kernel_size2, stride2, padding2))\n",
    "        if batch_norm2:\n",
    "            block.append(nn.BatchNorm2d(in_channels))\n",
    "        self.block = nn.Sequential(\n",
    "            *block\n",
    "        )\n",
    "    \n",
    "    def get_out_size(self, in_size):\n",
    "        for layer in (self.block[0], self.block[-1] if type(self.block[-1]) == nn.Conv2d else self.block[-2]):\n",
    "            in_size = (in_size - layer.kernel_size[0] + 2 * layer.padding[0]) // layer.stride[0] + 1\n",
    "        return in_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(x + self.block(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(model: nn.Module) -> list[nn.Module]:\n",
    "    modules_counter = {}\n",
    "    for m in model.modules():\n",
    "        name = m._get_name()\n",
    "        if name not in modules_counter:\n",
    "            modules_counter[name] = 0\n",
    "        modules_counter[name] += 1\n",
    "    return \"_\".join(f'{k}-{v}' for k, v in modules_counter.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "        img_size,\n",
    "        pool_kernel_size,\n",
    "        pool_stride,\n",
    "        *layers,\n",
    "        linears: list[int],\n",
    "        lr=0.01,\n",
    "        batch_size=800,\n",
    "        epoch_count=10,\n",
    "        softmax=True,\n",
    "        in_channels=1,\n",
    "        maxpool=True,\n",
    "        avgpool=False,\n",
    "    ) -> tuple[nn.Sequential, nn.CrossEntropyLoss, torch.optim.SGD, SummaryWriter]:\n",
    "    torch.manual_seed(0)\n",
    "    blocks = []\n",
    "    outs = img_size\n",
    "    for layer in layers:\n",
    "        blocks.append(\n",
    "            layer\n",
    "        )\n",
    "        tpe = type(layer)\n",
    "        if tpe == ResBlock:\n",
    "            outs = layer.get_out_size(outs)\n",
    "        elif tpe == nn.Conv2d:\n",
    "            outs = (outs - layer.kernel_size[0] + 2 * layer.padding[0]) // layer.stride[0] + 1\n",
    "            in_channels = layer.out_channels\n",
    "        elif tpe == nn.MaxPool2d:\n",
    "            outs = (outs - layer.kernel_size) // layer.stride + 1\n",
    "    if maxpool:\n",
    "        outs = (outs - pool_kernel_size) // pool_stride + 1\n",
    "        if avgpool:\n",
    "            blocks.append(nn.AvgPool2d(kernel_size=pool_kernel_size, stride=pool_stride))\n",
    "        else:\n",
    "            blocks.append(nn.MaxPool2d(kernel_size=pool_kernel_size, stride=pool_stride))\n",
    "    outs = outs * outs * in_channels\n",
    "    blocks.append(nn.Flatten(1))\n",
    "    for layer in linears:\n",
    "        blocks.append(nn.Linear(outs, layer))\n",
    "        blocks.append(nn.ReLU())\n",
    "        outs = layer\n",
    "    blocks.append(nn.Linear(outs, 10))\n",
    "    if softmax:\n",
    "        blocks.append(nn.Softmax())\n",
    "    model = nn.Sequential(\n",
    "        *blocks,\n",
    "    ).to(device)\n",
    "    er_f = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    # name = \"_\".join(m._get_name() for m in model.modules())\n",
    "    # name = f\"_{len(blocks_out_channels)}_{lr}_{blocks_kernel_size}_{blocks_stride}_{pool_kernel_size}_{pool_stride}\"\n",
    "    name = get_name(model)\n",
    "    print(name)\n",
    "    writer = SummaryWriter(comment=name)\n",
    "    return model, er_f, optim, writer, name, batch_size, epoch_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_summary(writer: SummaryWriter, model: nn.Module):\n",
    "    param_dict = {f\"layer_{i}\": str(m) for m, i in enumerate(get_name(model))}\n",
    "    param_table = pd.DataFrame(param_dict, index=[0])\n",
    "    for target_data, target_labels in target_loader:\n",
    "        target_labels = target_labels.max(1).indices\n",
    "    predicted = model(target_data)\n",
    "    predicted_labels = predicted.max(1).indices\n",
    "    confusion_matrix = torch.zeros(10, 10, device=device)\n",
    "    for i in range(len(predicted_labels)):\n",
    "        confusion_matrix[predicted_labels[i].long()][target_labels[i].long()] += 1\n",
    "    confusion_matrix = confusion_matrix.cpu()\n",
    "    fig = plt.gcf()\n",
    "    fig.clear()\n",
    "    ax = fig.add_subplot(111)\n",
    "    hist = predicted_labels[predicted_labels == target_labels]\n",
    "    error_hist = target_labels[predicted_labels != target_labels]\n",
    "    percent: torch.tensor = ((predicted_labels == target_labels).sum() / len(target_labels))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt=\"g\", ax=ax)\n",
    "    writer.add_figure(\"confusion_matrix\", fig)\n",
    "    writer.add_scalar(\"accuracy\", percent)\n",
    "    fig.clear()\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.histplot(hist.cpu(), stat=\"count\", discrete=True, bins=range(10), ax=ax)\n",
    "    writer.add_figure(\"right hist\", fig)\n",
    "    fig.clear()\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.histplot(error_hist.cpu(), stat=\"count\", discrete=True, bins=range(10), ax=ax)\n",
    "    writer.add_figure(\"error hist\", fig)\n",
    "    writer.add_text(\"param_table\", param_table.to_markdown())\n",
    "    writer.add_text(\"accuracy\", str(percent.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential-10_Conv2d-21_MaxPool2d-1_BatchNorm2d-3_ReLU-21_ResBlock-9_AvgPool2d-1_Flatten-1_Linear-1\n"
     ]
    }
   ],
   "source": [
    "models = (\n",
    "    # create_model(\n",
    "    #     32,\n",
    "    #     2,\n",
    "    #     2,\n",
    "    #     nn.Conv2d(3, 6, 5),\n",
    "    #     nn.MaxPool2d(2, 2),\n",
    "    #     nn.Conv2d(6, 16, 5),\n",
    "    #     linears=[],\n",
    "    #     lr=0.0001,\n",
    "    #     batch_size=30,\n",
    "    #     epoch_count=1,\n",
    "    # ), # 81 - 1000\n",
    "    # create_model(\n",
    "    #     32,\n",
    "    #     2,\n",
    "    #     2,\n",
    "    #     nn.Conv2d(3, 6, 5),\n",
    "    #     nn.ReLU(),\n",
    "    #     ResBlock(6, True, True, 10, 3, 3, 1, 1, in_size=32),\n",
    "    #     nn.MaxPool2d(2, 2),\n",
    "    #     nn.Conv2d(6, 16, 5),\n",
    "    #     nn.ReLU(),\n",
    "    #     ResBlock(16, True, True, 20, 3, 3, 1, 1, in_size=32),\n",
    "    #     nn.MaxPool2d(2, 2),\n",
    "    #     linears=[64, 32],\n",
    "    #     lr=0.001,\n",
    "    #     batch_size=4,\n",
    "    #     epoch_count=1,\n",
    "    #     maxpool=False,\n",
    "    #     softmax=False,\n",
    "    # ), # 81 - 1000\n",
    "    # create_model(\n",
    "    #     32,\n",
    "    #     2,\n",
    "    #     2,\n",
    "    #     ResBlock(3, True, True, 10, 3, 3, 1, 1, in_size=32),\n",
    "    #     nn.MaxPool2d(2, 2),\n",
    "    #     nn.ReLU(),\n",
    "    #     nn.Conv2d(3, 10, 3, 3),\n",
    "    #     ResBlock(10, True, True, 20, 3, 3, 1, 1, in_size=32),\n",
    "    #     nn.ReLU(),\n",
    "    #     linears=[64, 32],\n",
    "    #     lr=0.001,\n",
    "    #     batch_size=20,\n",
    "    #     epoch_count=1,\n",
    "    #     maxpool=True,\n",
    "    #     softmax=True,\n",
    "    # ), # 81 - 1000\n",
    "    create_model(\n",
    "        32,\n",
    "        2,\n",
    "        2,\n",
    "        nn.Conv2d(3, 8, 2, 2),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.BatchNorm2d(8),\n",
    "        nn.ReLU(),\n",
    "        ResBlock(8, False, False, 8, 3, 3, 1, 1, in_size=32),\n",
    "        nn.ReLU(),\n",
    "        ResBlock(8, False, False, 1, 3, 3, 1, 1, in_size=32),\n",
    "        nn.ReLU(),\n",
    "        ResBlock(8, False, False, 8, 3, 3, 1, 1, in_size=32),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(8, 16, 2, 2),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        ResBlock(16, False, False, 16, 3, 3, 1, 1, in_size=32),\n",
    "        nn.ReLU(),\n",
    "        ResBlock(16, False, False, 1, 3, 3, 1, 1, in_size=32),\n",
    "        nn.ReLU(),\n",
    "        ResBlock(16, False, False, 16, 3, 3, 1, 1, in_size=32),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(16, 32, 2, 2),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        ResBlock(32, False, False, 32, 3, 3, 1, 1, in_size=32),\n",
    "        nn.ReLU(),\n",
    "        ResBlock(32, False, False, 1, 3, 3, 1, 1, in_size=32),\n",
    "        nn.ReLU(),\n",
    "        ResBlock(32, False, False, 32, 3, 3, 1, 1, in_size=32),\n",
    "        nn.ReLU(),\n",
    "        linears=[],\n",
    "        lr=0.01,\n",
    "        batch_size=20,\n",
    "        epoch_count=1,\n",
    "        maxpool=True,\n",
    "        avgpool=True,\n",
    "        softmax=False,\n",
    "    ), # 81 - 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c41d9cacda46aa82e3bb3f91439321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b70444305b40cd8df8363d317a9c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20e50577d564f24bb668307e65c43b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, total_epochs)\n\u001b[1;32m     16\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, percent, total_epochs)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_data, target_labels \u001b[38;5;129;01min\u001b[39;00m target_loader:\n\u001b[1;32m     18\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m model(target_data)\n\u001b[1;32m     19\u001b[0m     percent: torch\u001b[38;5;241m.\u001b[39mtensor \u001b[38;5;241m=\u001b[39m ((predicted\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices \u001b[38;5;241m==\u001b[39m target_labels\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(target_labels))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torchvision/datasets/cifar.py:121\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img, target\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for model, er_f, optim, writer, name, batch_count, epoch_count in tqdm_notebook(models):\n",
    "        #  = create_model(28, *param)\n",
    "        torch.manual_seed(0)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_count, shuffle=True)\n",
    "        total_epochs = 0\n",
    "        for epoch in tqdm_notebook(range(epoch_count)):\n",
    "            for image, target in tqdm_notebook(data_loader, leave=False):\n",
    "                optim.zero_grad()\n",
    "                outs = model(image)\n",
    "                loss = er_f(outs, target)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                percent: torch.tensor = ((outs.max(1).indices == target.max(1).indices).sum() / len(target))\n",
    "                writer.add_scalar(\"loss\", loss, total_epochs)\n",
    "                writer.add_scalar(\"train_accuracy\", percent, total_epochs)\n",
    "                for target_data, target_labels in target_loader:\n",
    "                    predicted = model(target_data)\n",
    "                    percent: torch.tensor = ((predicted.max(1).indices == target_labels.max(1).indices).sum() / len(target_labels))\n",
    "                    writer.add_scalar(\"test_accuracy\", percent, total_epochs)\n",
    "                total_epochs += 1\n",
    "finally:\n",
    "    write_summary(writer, model)\n",
    "    torch.save(model, f\"model_{repr(dataset.__class__).split('.')[-1][:-2]}_{percent:.2f}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "data_loader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "epoches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "data_loader = DataLoader(dataset, batch_size=1000, shuffle=True)\n",
    "epoches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=500, shuffle=True)\n",
    "epoches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78a2a6dab6847299b7a29765c16c239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2defb1fe77574b388d86b451e1c922ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[158., 159., 165.,  ..., 137., 126., 116.],\n",
      "          [152., 151., 159.,  ..., 136., 125., 119.],\n",
      "          [151., 151., 158.,  ..., 139., 130., 120.],\n",
      "          ...,\n",
      "          [ 68.,  42.,  31.,  ...,  38.,  13.,  40.],\n",
      "          [ 61.,  49.,  35.,  ...,  26.,  29.,  20.],\n",
      "          [ 54.,  56.,  45.,  ...,  24.,  34.,  21.]],\n",
      "\n",
      "         [[112., 111., 116.,  ...,  95.,  91.,  85.],\n",
      "          [112., 110., 114.,  ...,  95.,  91.,  88.],\n",
      "          [110., 109., 111.,  ...,  98.,  95.,  89.],\n",
      "          ...,\n",
      "          [124., 100.,  88.,  ...,  97.,  64.,  85.],\n",
      "          [116., 102.,  85.,  ...,  82.,  82.,  64.],\n",
      "          [107., 105.,  89.,  ...,  77.,  84.,  67.]],\n",
      "\n",
      "         [[ 49.,  47.,  51.,  ...,  36.,  36.,  33.],\n",
      "          [ 51.,  40.,  45.,  ...,  31.,  32.,  34.],\n",
      "          [ 47.,  33.,  36.,  ...,  34.,  34.,  33.],\n",
      "          ...,\n",
      "          [177., 148., 137.,  ..., 146., 108., 127.],\n",
      "          [168., 148., 132.,  ..., 130., 126., 107.],\n",
      "          [160., 149., 132.,  ..., 124., 129., 110.]]],\n",
      "\n",
      "\n",
      "        [[[235., 231., 232.,  ..., 233., 233., 232.],\n",
      "          [238., 235., 235.,  ..., 236., 236., 235.],\n",
      "          [237., 234., 234.,  ..., 235., 235., 234.],\n",
      "          ...,\n",
      "          [ 87.,  43.,  19.,  ..., 169., 182., 188.],\n",
      "          [ 82.,  46.,  36.,  ..., 174., 185., 187.],\n",
      "          [ 85.,  62.,  58.,  ..., 168., 180., 186.]],\n",
      "\n",
      "         [[235., 231., 232.,  ..., 233., 233., 232.],\n",
      "          [238., 235., 235.,  ..., 236., 236., 235.],\n",
      "          [237., 234., 234.,  ..., 235., 235., 234.],\n",
      "          ...,\n",
      "          [ 99.,  51.,  23.,  ..., 184., 197., 202.],\n",
      "          [ 96.,  57.,  44.,  ..., 189., 200., 202.],\n",
      "          [101.,  75.,  67.,  ..., 183., 195., 200.]],\n",
      "\n",
      "         [[235., 231., 232.,  ..., 233., 233., 232.],\n",
      "          [238., 235., 235.,  ..., 236., 236., 235.],\n",
      "          [237., 234., 234.,  ..., 235., 235., 234.],\n",
      "          ...,\n",
      "          [ 89.,  37.,  11.,  ..., 179., 193., 201.],\n",
      "          [ 82.,  36.,  22.,  ..., 183., 196., 200.],\n",
      "          [ 83.,  48.,  38.,  ..., 178., 191., 199.]]],\n",
      "\n",
      "\n",
      "        [[[158., 158., 139.,  ..., 228., 237., 238.],\n",
      "          [170., 172., 151.,  ..., 232., 246., 246.],\n",
      "          [174., 176., 157.,  ..., 230., 250., 245.],\n",
      "          ...,\n",
      "          [ 31.,  30.,  26.,  ...,  37.,   9.,   4.],\n",
      "          [ 23.,  27.,  25.,  ...,  19.,   4.,   5.],\n",
      "          [ 28.,  30.,  32.,  ...,   5.,   4.,   7.]],\n",
      "\n",
      "         [[190., 187., 166.,  ..., 231., 239., 241.],\n",
      "          [200., 199., 176.,  ..., 232., 246., 247.],\n",
      "          [201., 200., 179.,  ..., 229., 249., 244.],\n",
      "          ...,\n",
      "          [ 40.,  39.,  35.,  ...,  40.,  13.,   7.],\n",
      "          [ 34.,  38.,  36.,  ...,  20.,   6.,   7.],\n",
      "          [ 41.,  43.,  45.,  ...,   6.,   5.,   8.]],\n",
      "\n",
      "         [[222., 218., 194.,  ..., 234., 243., 246.],\n",
      "          [229., 226., 201.,  ..., 236., 250., 251.],\n",
      "          [225., 222., 199.,  ..., 232., 251., 247.],\n",
      "          ...,\n",
      "          [ 45.,  44.,  40.,  ...,  46.,  14.,   5.],\n",
      "          [ 39.,  43.,  41.,  ...,  24.,   3.,   3.],\n",
      "          [ 47.,  50.,  52.,  ...,   8.,   3.,   7.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 20.,  19.,  15.,  ...,  10.,  12.,  13.],\n",
      "          [ 21.,  20.,  18.,  ...,  10.,  10.,  12.],\n",
      "          [ 21.,  21.,  20.,  ...,  12.,  12.,  13.],\n",
      "          ...,\n",
      "          [ 33.,  34.,  34.,  ...,  28.,  29.,  23.],\n",
      "          [ 33.,  34.,  34.,  ...,  27.,  27.,  25.],\n",
      "          [ 31.,  32.,  33.,  ...,  24.,  26.,  25.]],\n",
      "\n",
      "         [[ 15.,  14.,  14.,  ...,   9.,  11.,  12.],\n",
      "          [ 16.,  16.,  17.,  ...,   9.,   9.,  11.],\n",
      "          [ 16.,  17.,  18.,  ...,  11.,  11.,  12.],\n",
      "          ...,\n",
      "          [ 25.,  26.,  26.,  ...,  25.,  25.,  20.],\n",
      "          [ 25.,  26.,  26.,  ...,  24.,  24.,  22.],\n",
      "          [ 23.,  24.,  25.,  ...,  23.,  23.,  20.]],\n",
      "\n",
      "         [[ 12.,  11.,  11.,  ...,   7.,   9.,  10.],\n",
      "          [ 13.,  13.,  12.,  ...,   7.,   7.,   9.],\n",
      "          [ 13.,  12.,  11.,  ...,   9.,   9.,  10.],\n",
      "          ...,\n",
      "          [ 13.,  15.,  15.,  ...,  52.,  58.,  42.],\n",
      "          [ 14.,  15.,  15.,  ...,  52.,  56.,  47.],\n",
      "          [ 12.,  13.,  14.,  ...,  50.,  53.,  47.]]],\n",
      "\n",
      "\n",
      "        [[[ 25.,  15.,  23.,  ...,  61.,  92.,  75.],\n",
      "          [ 12.,  20.,  24.,  ..., 115., 149., 104.],\n",
      "          [ 12.,  15.,  34.,  ..., 154., 157., 116.],\n",
      "          ...,\n",
      "          [100., 103., 104.,  ...,  97.,  98.,  91.],\n",
      "          [103., 104., 107.,  ..., 101.,  99.,  92.],\n",
      "          [ 95.,  95., 101.,  ...,  93.,  95.,  92.]],\n",
      "\n",
      "         [[ 40.,  36.,  41.,  ...,  82., 113.,  89.],\n",
      "          [ 25.,  37.,  36.,  ..., 134., 168., 117.],\n",
      "          [ 25.,  29.,  40.,  ..., 172., 175., 129.],\n",
      "          ...,\n",
      "          [129., 132., 134.,  ..., 128., 126., 121.],\n",
      "          [132., 131., 135.,  ..., 132., 127., 121.],\n",
      "          [126., 123., 128.,  ..., 124., 123., 120.]],\n",
      "\n",
      "         [[ 12.,   3.,  18.,  ...,  78., 112.,  92.],\n",
      "          [  6.,   7.,  15.,  ..., 138., 177., 131.],\n",
      "          [ 11.,   6.,  24.,  ..., 182., 192., 151.],\n",
      "          ...,\n",
      "          [ 81.,  84.,  86.,  ...,  84.,  84.,  79.],\n",
      "          [ 83.,  83.,  87.,  ...,  87.,  84.,  79.],\n",
      "          [ 78.,  76.,  81.,  ...,  80.,  81.,  80.]]],\n",
      "\n",
      "\n",
      "        [[[ 73.,  98.,  99.,  ..., 135., 135., 203.],\n",
      "          [ 69.,  84.,  68.,  ...,  85.,  71., 120.],\n",
      "          [ 69.,  90.,  62.,  ...,  74.,  53.,  62.],\n",
      "          ...,\n",
      "          [123., 132., 129.,  ..., 108.,  62.,  27.],\n",
      "          [115., 123., 129.,  ..., 115.,  66.,  27.],\n",
      "          [116., 121., 129.,  ..., 116.,  68.,  27.]],\n",
      "\n",
      "         [[ 78., 103., 106.,  ..., 150., 149., 215.],\n",
      "          [ 73.,  89.,  75.,  ...,  95.,  82., 133.],\n",
      "          [ 73.,  95.,  71.,  ...,  81.,  62.,  74.],\n",
      "          ...,\n",
      "          [128., 132., 128.,  ..., 107.,  60.,  27.],\n",
      "          [121., 124., 126.,  ..., 116.,  65.,  27.],\n",
      "          [120., 122., 128.,  ..., 115.,  65.,  26.]],\n",
      "\n",
      "         [[ 75., 113., 114.,  ..., 152., 154., 223.],\n",
      "          [ 70.,  97.,  81.,  ...,  89.,  80., 135.],\n",
      "          [ 70., 100.,  74.,  ...,  70.,  54.,  69.],\n",
      "          ...,\n",
      "          [ 96., 102., 100.,  ...,  88.,  55.,  28.],\n",
      "          [ 91.,  95.,  99.,  ...,  94.,  59.,  27.],\n",
      "          [ 90.,  94., 101.,  ...,  94.,  58.,  26.]]]], device='cuda:0') tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, total_epochs)\n\u001b[1;32m     11\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, percent, total_epochs)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_data, target_labels \u001b[38;5;129;01min\u001b[39;00m target_loader:\n\u001b[1;32m     13\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m model(target_data)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(target_data, target_labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torchvision/datasets/cifar.py:115\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:3093\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3090\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3091\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n\u001b[0;32m-> 3093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:3009\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3006\u001b[0m         im\u001b[38;5;241m.\u001b[39mreadonly \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3007\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[0;32m-> 3009\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:2951\u001b[0m, in \u001b[0;36mfrombytes\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2948\u001b[0m     args \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   2950\u001b[0m im \u001b[38;5;241m=\u001b[39m new(mode, size)\n\u001b[0;32m-> 2951\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrombytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:798\u001b[0m, in \u001b[0;36mImage.frombytes\u001b[0;34m(self, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m    795\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# unpack data\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[43m_getdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m d\u001b[38;5;241m.\u001b[39msetimage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim)\n\u001b[1;32m    800\u001b[0m s \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mdecode(data)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:392\u001b[0m, in \u001b[0;36m_getdecoder\u001b[0;34m(mode, decoder_name, args, extra)\u001b[0m\n\u001b[1;32m    390\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoder_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not available\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for epoch in tqdm_notebook(range(epoches)):\n",
    "        for image, target in tqdm_notebook(data_loader, leave=False):\n",
    "            optim.zero_grad()\n",
    "            outs = model(image)\n",
    "            loss = er_f(outs, target)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            percent: torch.tensor = ((outs.max(1).indices == target.max(1).indices).sum() / len(target))\n",
    "            writer.add_scalar(\"loss\", loss, total_epochs)\n",
    "            writer.add_scalar(\"train_accuracy\", percent, total_epochs)\n",
    "            for target_data, target_labels in target_loader:\n",
    "                predicted = model(target_data)\n",
    "                percent: torch.tensor = ((predicted.max(1).indices == target_labels.max(1).indices).sum() / len(target_labels))\n",
    "                writer.add_scalar(\"test_accuracy\", percent, total_epochs)\n",
    "            total_epochs += 1\n",
    "finally:\n",
    "    write_summary(writer, model)\n",
    "    torch.save(model, f\"model_{repr(dataset.__class__).split('.')[-1][:-2]}_{percent:.2f}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(model, f\"model_{repr(dataset.__class__).split('.')[-1][:-2]}_{name:.2f}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
