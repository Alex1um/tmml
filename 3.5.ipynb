{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron via Torch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)  \n",
    "(x_train_raw, y_train_raw),(x_test_raw, y_test_raw) = MnistDataloader(\n",
    "    \"data/mnist/train-images.idx3-ubyte\",\n",
    "    \"data/mnist/train-labels.idx1-ubyte\",\n",
    "    \"data/mnist/t10k-images.idx3-ubyte\",\n",
    "    \"data/mnist/t10k-labels.idx1-ubyte\"\n",
    "    ).load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000]), torch.uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.tensor(np.array(x_train_raw).reshape(60000, 28*28))\n",
    "y_train = torch.tensor(np.array(y_train_raw))\n",
    "x_test = torch.tensor(np.array(x_test_raw).reshape(10000, 28*28))\n",
    "y_test = torch.tensor(np.array(y_test_raw))\n",
    "x_train.shape, y_train.shape, x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 10),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "vals = torch.load(\"84class.pth\")\n",
    "model.load_state_dict(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 10),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "# er_f = nn.HuberLoss()\n",
    "er_f = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.1, momentum=.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "for x, y in zip(x_train[:N], y_train[:N]):\n",
    "    target = torch.zeros(10)\n",
    "    target[int(y)] = 1\n",
    "    # y_pred = torch.argmax(y_pred)\n",
    "    optim.zero_grad()\n",
    "    train = Variable(x.float(), requires_grad=True)\n",
    "    target = Variable(target.float(), requires_grad=False)\n",
    "    y_pred = model(train).float()\n",
    "    loss = er_f(y_pred, target)\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.ones(x_train.shape[0], 10) * 0\n",
    "for i, y in zip(range(x_train.shape[0]), y_train):\n",
    "    target[i, int(y)] = 1\n",
    "target = Variable(target.float(), requires_grad=False)\n",
    "train = Variable(x_train.float(), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0301, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0301, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0300, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0300, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<HuberLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[317], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(train[current_batch:current_batch \u001b[38;5;241m+\u001b[39m batch])\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m er_f(y_pred, target[current_batch:current_batch \u001b[38;5;241m+\u001b[39m batch])\n\u001b[0;32m----> 7\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      9\u001b[0m current_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch = 30000\n",
    "current_batch = 0\n",
    "for epich in range(400):\n",
    "    optim.zero_grad()\n",
    "    y_pred = model(train[current_batch:current_batch + batch]).float()\n",
    "    loss = er_f(y_pred, target[current_batch:current_batch + batch])\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    current_batch += batch\n",
    "    current_batch %= x_train.shape[0]\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8801)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(torch.argmax(model(x_test.float()), 1), y_test).sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors = {i: 0 for i in range(10)}\n",
    "for true, predicted in zip(y_test, torch.argmax(model(x_test.float()), 1)):\n",
    "    true = int(true)\n",
    "    errors[true] += true != int(predicted)\n",
    "plt.xticks(range(10))\n",
    "plt.bar(errors.keys(), errors.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"45class.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
