{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron via Torch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)  \n",
    "(x_train_raw, y_train_raw),(x_test_raw, y_test_raw) = MnistDataloader(\n",
    "    \"data/mnist/train-images.idx3-ubyte\",\n",
    "    \"data/mnist/train-labels.idx1-ubyte\",\n",
    "    \"data/mnist/t10k-images.idx3-ubyte\",\n",
    "    \"data/mnist/t10k-labels.idx1-ubyte\"\n",
    "    ).load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000]), torch.uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.tensor(np.array(x_train_raw).reshape(60000, 28*28))\n",
    "y_train = torch.tensor(np.array(y_train_raw))\n",
    "x_test = torch.tensor(np.array(x_test_raw).reshape(10000, 28*28))\n",
    "y_test = torch.tensor(np.array(y_test_raw))\n",
    "x_train.shape, y_train.shape, x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 10),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "# er_f = nn.HuberLoss()\n",
    "er_f = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "for x, y in zip(x_train[:N], y_train[:N]):\n",
    "    target = torch.ones(10) * -1\n",
    "    target[int(y)] = 1\n",
    "    # y_pred = torch.argmax(y_pred)\n",
    "    optim.zero_grad()\n",
    "    train = Variable(x.float(), requires_grad=True)\n",
    "    target = Variable(target.float(), requires_grad=False)\n",
    "    y_pred = model(train).float()\n",
    "    loss = er_f(y_pred, target)\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.ones(x_train.shape[0], 10) * 0\n",
    "for i, y in zip(range(x_train.shape[0]), y_train):\n",
    "    target[i, int(y)] = 1\n",
    "target = Variable(target.float(), requires_grad=False)\n",
    "train = Variable(x_train.float(), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5851, grad_fn=<DivBackward1>)\n",
      "tensor(1.5849, grad_fn=<DivBackward1>)\n",
      "tensor(1.5849, grad_fn=<DivBackward1>)\n",
      "tensor(1.5848, grad_fn=<DivBackward1>)\n",
      "tensor(1.5848, grad_fn=<DivBackward1>)\n",
      "tensor(1.5846, grad_fn=<DivBackward1>)\n",
      "tensor(1.5846, grad_fn=<DivBackward1>)\n",
      "tensor(1.5844, grad_fn=<DivBackward1>)\n",
      "tensor(1.5845, grad_fn=<DivBackward1>)\n",
      "tensor(1.5843, grad_fn=<DivBackward1>)\n",
      "tensor(1.5844, grad_fn=<DivBackward1>)\n",
      "tensor(1.5844, grad_fn=<DivBackward1>)\n",
      "tensor(1.5845, grad_fn=<DivBackward1>)\n",
      "tensor(1.5846, grad_fn=<DivBackward1>)\n",
      "tensor(1.5843, grad_fn=<DivBackward1>)\n",
      "tensor(1.5843, grad_fn=<DivBackward1>)\n",
      "tensor(1.5842, grad_fn=<DivBackward1>)\n",
      "tensor(1.5842, grad_fn=<DivBackward1>)\n",
      "tensor(1.5839, grad_fn=<DivBackward1>)\n",
      "tensor(1.5839, grad_fn=<DivBackward1>)\n",
      "tensor(1.5838, grad_fn=<DivBackward1>)\n",
      "tensor(1.5837, grad_fn=<DivBackward1>)\n",
      "tensor(1.5836, grad_fn=<DivBackward1>)\n",
      "tensor(1.5835, grad_fn=<DivBackward1>)\n",
      "tensor(1.5834, grad_fn=<DivBackward1>)\n",
      "tensor(1.5832, grad_fn=<DivBackward1>)\n",
      "tensor(1.5832, grad_fn=<DivBackward1>)\n",
      "tensor(1.5830, grad_fn=<DivBackward1>)\n",
      "tensor(1.5830, grad_fn=<DivBackward1>)\n",
      "tensor(1.5828, grad_fn=<DivBackward1>)\n",
      "tensor(1.5829, grad_fn=<DivBackward1>)\n",
      "tensor(1.5827, grad_fn=<DivBackward1>)\n",
      "tensor(1.5827, grad_fn=<DivBackward1>)\n",
      "tensor(1.5826, grad_fn=<DivBackward1>)\n",
      "tensor(1.5826, grad_fn=<DivBackward1>)\n",
      "tensor(1.5824, grad_fn=<DivBackward1>)\n",
      "tensor(1.5824, grad_fn=<DivBackward1>)\n",
      "tensor(1.5823, grad_fn=<DivBackward1>)\n",
      "tensor(1.5823, grad_fn=<DivBackward1>)\n",
      "tensor(1.5822, grad_fn=<DivBackward1>)\n",
      "tensor(1.5823, grad_fn=<DivBackward1>)\n",
      "tensor(1.5821, grad_fn=<DivBackward1>)\n",
      "tensor(1.5822, grad_fn=<DivBackward1>)\n",
      "tensor(1.5821, grad_fn=<DivBackward1>)\n",
      "tensor(1.5822, grad_fn=<DivBackward1>)\n",
      "tensor(1.5821, grad_fn=<DivBackward1>)\n",
      "tensor(1.5821, grad_fn=<DivBackward1>)\n",
      "tensor(1.5821, grad_fn=<DivBackward1>)\n",
      "tensor(1.5820, grad_fn=<DivBackward1>)\n",
      "tensor(1.5818, grad_fn=<DivBackward1>)\n",
      "tensor(1.5818, grad_fn=<DivBackward1>)\n",
      "tensor(1.5816, grad_fn=<DivBackward1>)\n",
      "tensor(1.5815, grad_fn=<DivBackward1>)\n",
      "tensor(1.5813, grad_fn=<DivBackward1>)\n",
      "tensor(1.5813, grad_fn=<DivBackward1>)\n",
      "tensor(1.5811, grad_fn=<DivBackward1>)\n",
      "tensor(1.5811, grad_fn=<DivBackward1>)\n",
      "tensor(1.5809, grad_fn=<DivBackward1>)\n",
      "tensor(1.5810, grad_fn=<DivBackward1>)\n",
      "tensor(1.5808, grad_fn=<DivBackward1>)\n",
      "tensor(1.5809, grad_fn=<DivBackward1>)\n",
      "tensor(1.5807, grad_fn=<DivBackward1>)\n",
      "tensor(1.5808, grad_fn=<DivBackward1>)\n",
      "tensor(1.5807, grad_fn=<DivBackward1>)\n",
      "tensor(1.5807, grad_fn=<DivBackward1>)\n",
      "tensor(1.5806, grad_fn=<DivBackward1>)\n",
      "tensor(1.5807, grad_fn=<DivBackward1>)\n",
      "tensor(1.5806, grad_fn=<DivBackward1>)\n",
      "tensor(1.5807, grad_fn=<DivBackward1>)\n",
      "tensor(1.5806, grad_fn=<DivBackward1>)\n",
      "tensor(1.5806, grad_fn=<DivBackward1>)\n",
      "tensor(1.5806, grad_fn=<DivBackward1>)\n",
      "tensor(1.5805, grad_fn=<DivBackward1>)\n",
      "tensor(1.5805, grad_fn=<DivBackward1>)\n",
      "tensor(1.5803, grad_fn=<DivBackward1>)\n",
      "tensor(1.5802, grad_fn=<DivBackward1>)\n",
      "tensor(1.5801, grad_fn=<DivBackward1>)\n",
      "tensor(1.5799, grad_fn=<DivBackward1>)\n",
      "tensor(1.5798, grad_fn=<DivBackward1>)\n",
      "tensor(1.5797, grad_fn=<DivBackward1>)\n",
      "tensor(1.5797, grad_fn=<DivBackward1>)\n",
      "tensor(1.5795, grad_fn=<DivBackward1>)\n",
      "tensor(1.5796, grad_fn=<DivBackward1>)\n",
      "tensor(1.5794, grad_fn=<DivBackward1>)\n",
      "tensor(1.5795, grad_fn=<DivBackward1>)\n",
      "tensor(1.5793, grad_fn=<DivBackward1>)\n",
      "tensor(1.5794, grad_fn=<DivBackward1>)\n",
      "tensor(1.5792, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[229], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(train)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m er_f(y_pred, target)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epich in range(1000):\n",
    "    optim.zero_grad()\n",
    "    y_pred = model(train).float()\n",
    "    loss = er_f(y_pred, target)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8753)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(torch.argmax(model(x_test.float()), 1), y_test).sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors = {i: 0 for i in range(10)}\n",
    "for true, predicted in zip(y_test, torch.argmax(model(x_test.float()), 1)):\n",
    "    true = int(true)\n",
    "    errors[true] += true != int(predicted)\n",
    "plt.xticks(range(10))\n",
    "plt.bar(errors.keys(), errors.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
