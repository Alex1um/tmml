{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST, mnist, CIFAR10\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTargetTransform:\n",
    "    def __init__(self, num_classes=10):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __call__(self, target):\n",
    "        new_target = torch.zeros(self.num_classes, dtype=torch.float, device=device)\n",
    "        new_target[target] = 1\n",
    "        return new_target\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Lambda(lambda x: x.float().to(device))\n",
    "])\n",
    "\n",
    "# data_loader = DataLoader(dataset, batch_size=800, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mnist.FashionMNIST(\"data\", download=True, train=True, transform=transform, target_transform=CustomTargetTransform())\n",
    "dataset_target = mnist.FashionMNIST(\"data\", download=True, train=False, transform=transforms.PILToTensor())\n",
    "# dataset = CIFAR10(\"data\", download=True, train=True, transform=transform, target_transform=CustomTargetTransform())\n",
    "# dataset_target = CIFAR10(\"data\", download=True, train=False, transform=transforms.PILToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4927/3376170973.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_data = torch.tensor(dataset_target.data).unsqueeze(1).float().to(device)\n",
      "/tmp/ipykernel_4927/3376170973.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_labels = torch.tensor(dataset_target.targets).float().to(device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 1, 28, 28]), torch.Size([10000]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_data = torch.tensor(dataset_target.data).swapaxes(3, 1).float().to(device)\n",
    "target_data = torch.tensor(dataset_target.data).unsqueeze(1).float().to(device)\n",
    "target_labels = torch.tensor(dataset_target.targets).float().to(device)\n",
    "target_data.shape, target_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, batch_norm1, batch_norm2, inter_channels, kernel_size1, kernel_size2, stride1, stride2, padding1=1, padding2=1, in_size=28):\n",
    "        super().__init__()\n",
    "        block = [\n",
    "            nn.Conv2d(in_channels, inter_channels, kernel_size1, stride1, padding1),\n",
    "        ]\n",
    "        if batch_norm1:\n",
    "            block.append(nn.BatchNorm2d(inter_channels))\n",
    "        block.append(nn.ReLU())\n",
    "        block.append(nn.Conv2d(inter_channels, in_channels, kernel_size2, stride2, padding2))\n",
    "        if batch_norm2:\n",
    "            block.append(nn.BatchNorm2d(in_channels))\n",
    "        self.block = nn.Sequential(\n",
    "            *block\n",
    "        )\n",
    "    \n",
    "    def get_out_size(self, in_size):\n",
    "        for layer in (self.block[0], self.block[-1] if type(self.block[-1]) == nn.Conv2d else self.block[-2]):\n",
    "            in_size = (in_size - layer.kernel_size[0] + 2 * layer.padding[0]) // layer.stride[0] + 1\n",
    "        return in_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(x + self.block(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(model: nn.Module) -> list[nn.Module]:\n",
    "    skip = 1\n",
    "    names = []\n",
    "    for m in model.modules():\n",
    "        if skip > 0:\n",
    "            skip -= 1\n",
    "            continue\n",
    "        names.append(m)\n",
    "        if len(tuple(m.modules())) > 1:\n",
    "            skip = len(tuple(m.modules())) - 1\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "        img_size,\n",
    "        pool_kernel_size,\n",
    "        pool_stride,\n",
    "        *layers,\n",
    "        linears: list[int],\n",
    "        lr=0.01,\n",
    "        batch_size=800,\n",
    "        epoch_count=10,\n",
    "        softmax=True,\n",
    "    ) -> tuple[nn.Sequential, nn.CrossEntropyLoss, torch.optim.SGD, SummaryWriter]:\n",
    "    torch.manual_seed(0)\n",
    "    blocks = []\n",
    "    in_channels = 1\n",
    "    outs = img_size\n",
    "    for layer in layers:\n",
    "        blocks.append(\n",
    "            layer\n",
    "        )\n",
    "        tpe = type(layer)\n",
    "        if tpe == ResBlock:\n",
    "            outs = layer.get_out_size(outs)\n",
    "        elif tpe == nn.Conv2d:\n",
    "            outs = (outs - layer.kernel_size[0] + 2 * layer.padding[0]) // layer.stride[0] + 1\n",
    "            in_channels = layer.out_channels\n",
    "        elif tpe == nn.MaxPool2d:\n",
    "            outs = (outs - layer.kernel_size) // layer.stride + 1\n",
    "    outs = (outs - pool_kernel_size) // pool_stride + 1\n",
    "    outs = outs * outs * in_channels\n",
    "    blocks.append(nn.MaxPool2d(kernel_size=pool_kernel_size, stride=pool_stride))\n",
    "    blocks.append(nn.Flatten(1))\n",
    "    for layer in linears:\n",
    "        blocks.append(nn.Linear(outs, layer))\n",
    "        outs = layer\n",
    "    blocks.append(nn.Linear(outs, 10))\n",
    "    if softmax:\n",
    "        blocks.append(nn.Softmax())\n",
    "    model = nn.Sequential(\n",
    "        *blocks,\n",
    "    ).to(device)\n",
    "    er_f = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    # name = \"_\".join(m._get_name() for m in model.modules())\n",
    "    # name = f\"_{len(blocks_out_channels)}_{lr}_{blocks_kernel_size}_{blocks_stride}_{pool_kernel_size}_{pool_stride}\"\n",
    "    name = \"_\".join(m._get_name() for m in get_name(model))\n",
    "    print(name)\n",
    "    writer = SummaryWriter(comment=name)\n",
    "    return model, er_f, optim, writer, name, batch_size, epoch_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_summary(writer: SummaryWriter, model: nn.Module):\n",
    "    param_dict = {f\"layer_{i}\": str(m) for m, i in enumerate(get_name(model))}\n",
    "    param_table = pd.DataFrame(param_dict, index=[0])\n",
    "    predicted = model(target_data)\n",
    "    predicted_labels = predicted.max(1).indices\n",
    "    confusion_matrix = torch.zeros(10, 10, device=device)\n",
    "    for i in range(len(predicted_labels)):\n",
    "        confusion_matrix[predicted_labels[i].long()][target_labels[i].long()] += 1\n",
    "    confusion_matrix = confusion_matrix.cpu()\n",
    "    fig = plt.gcf()\n",
    "    fig.clear()\n",
    "    ax = fig.add_subplot(111)\n",
    "    hist = predicted_labels[predicted_labels == target_labels]\n",
    "    error_hist = target_labels[predicted_labels != target_labels]\n",
    "    percent: torch.tensor = ((predicted_labels == target_labels).sum() / len(target_labels))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt=\"g\", ax=ax)\n",
    "    writer.add_figure(\"confusion_matrix\", fig)\n",
    "    writer.add_scalar(\"accuracy\", percent)\n",
    "    fig.clear()\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.histplot(hist.cpu(), stat=\"count\", discrete=True, bins=range(10), ax=ax)\n",
    "    writer.add_figure(\"right hist\", fig)\n",
    "    fig.clear()\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.histplot(error_hist.cpu(), stat=\"count\", discrete=True, bins=range(10), ax=ax)\n",
    "    writer.add_figure(\"error hist\", fig)\n",
    "    writer.add_text(\"param_table\", param_table.to_markdown())\n",
    "    writer.add_text(\"accuracy\", str(percent.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d_ResBlock_MaxPool2d_Conv2d_ResBlock_MaxPool2d_Flatten_Linear_Softmax\n"
     ]
    }
   ],
   "source": [
    "models = (\n",
    "    # create_model(\n",
    "    #     28,\n",
    "    #     2,\n",
    "    #     2,\n",
    "    #     nn.Conv2d(1, 3, 3, 1, 1, 1),\n",
    "    #     ResBlock(3, 3, 3, 3, 1, 1),\n",
    "    #     nn.Conv2d(3, 6, 3, 1, 1, 1),\n",
    "    #     ResBlock(6, 6, 3, 3, 1, 1),\n",
    "    #     lr=0.1,\n",
    "    #     batch_size=800,\n",
    "    #     epoch_count=15,\n",
    "    # ), # 74 - 251\n",
    "    # create_model(\n",
    "    #     28,\n",
    "    #     2,\n",
    "    #     2,\n",
    "    #     nn.Conv2d(1, 3, 3, 1, 1, 1),\n",
    "    #     ResBlock(3, False, False, 3, 3, 3, 1, 1),\n",
    "    #     nn.MaxPool2d(2, 2),\n",
    "    #     nn.Conv2d(3, 6, 3, 1, 1, 1),\n",
    "    #     ResBlock(6, False, False, 6, 3, 3, 1, 1),\n",
    "    #     lr=0.1,\n",
    "    #     batch_size=800,\n",
    "    #     epoch_count=10,\n",
    "    # ), # 79 - 500\n",
    "    # create_model(\n",
    "    #     28,\n",
    "    #     2,\n",
    "    #     2,\n",
    "    #     nn.Conv2d(1, 3, 3, 1, 1, 1),\n",
    "    #     ResBlock(3, 3, 3, 3, 1, 1),\n",
    "    #     nn.ReLU(),\n",
    "    #     nn.MaxPool2d(2, 2),\n",
    "    #     nn.Conv2d(3, 6, 3, 1, 1, 1),\n",
    "    #     ResBlock(6, 6, 3, 3, 1, 1),\n",
    "    #     lr=0.1,\n",
    "    #     batch_size=800,\n",
    "    #     epoch_count=10,\n",
    "    # ), # 70 - 300\n",
    "    # create_model(\n",
    "    #     28,\n",
    "    #     2,\n",
    "    #     2,\n",
    "    #     nn.Conv2d(1, 3, 3, 1, 1, 1),\n",
    "    #     ResBlock(3, 3, 3, 3, 1, 1),\n",
    "    #     nn.MaxPool2d(2, 2),\n",
    "    #     nn.Conv2d(3, 6, 3, 1, 1, 1),\n",
    "    #     ResBlock(6, 6, 3, 3, 1, 1),\n",
    "    #     nn.MaxPool2d(2, 2),\n",
    "    #     nn.Conv2d(6, 10, 3, 1, 1, 1),\n",
    "    #     ResBlock(10, 10, 3, 3, 1, 1),\n",
    "    #     lr=0.1,\n",
    "    #     batch_size=800,\n",
    "    #     epoch_count=10,\n",
    "    # ), # 76 - 500\n",
    "    # create_model(\n",
    "    #     28,\n",
    "    #     2,\n",
    "    #     2,6\n",
    "    #     nn.Conv2d(1, 3, 3, 1, 1, 1),\n",
    "    #     ResBlock(3, True, True, 3, 3, 3, 1, 1),\n",
    "    #     nn.MaxPool2d(2, 2),\n",
    "    #     nn.Conv2d(3, 6, 3, 1, 1, 1),\n",
    "    #     ResBlock(6, True, True, 6, 3, 3, 1, 1),\n",
    "    #     lr=0.1,\n",
    "    #     batch_size=800,\n",
    "    #     epoch_count=10,\n",
    "    # ), # 65 - 100\n",
    "    # create_model(\n",
    "    #     28,\n",
    "    #     2,\n",
    "    #     2,\n",
    "    #     nn.Conv2d(1, 3, 3, 1, 1, 1),\n",
    "    #     ResBlock(3, True, True, 3, 3, 3, 1, 1),\n",
    "    #     nn.MaxPool2d(2, 2),\n",
    "    #     nn.Conv2d(3, 6, 3, 1, 1, 1),\n",
    "    #     ResBlock(6, True, True, 6, 3, 3, 1, 1),\n",
    "    #     lr=0.001,\n",
    "    #     batch_size=30,\n",
    "    #     epoch_count=10,\n",
    "    # ), # 81 - 1000\n",
    "    create_model(\n",
    "        28,\n",
    "        2,\n",
    "        2,\n",
    "        # ResBlock(1, True, True, 3, 3, 3, 1, 1),\n",
    "        nn.Conv2d(1, 3, 3, 1, 1, 1),\n",
    "        ResBlock(3, True, True, 10, 3, 3, 1, 1),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "        nn.Conv2d(3, 6, 3, 1, 1),\n",
    "        ResBlock(6, True, True, 20, 3, 3, 1, 1, 1, 1),\n",
    "        linears=[],\n",
    "        lr=0.001,\n",
    "        batch_size=30,\n",
    "        # lr=0.001,\n",
    "        # batch_size=30,\n",
    "        epoch_count=1,\n",
    "    ), # 81 - 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57558a0735984a238ec8033c935b0168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6b78f25bef49dba800ca173b46114b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca865dac746e4abd83c7010d190fcb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex1um/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "/home/alex1um/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m                 predicted_labels \u001b[38;5;241m=\u001b[39m predicted\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\n\u001b[1;32m     21\u001b[0m                 percent: torch\u001b[38;5;241m.\u001b[39mtensor \u001b[38;5;241m=\u001b[39m ((predicted_labels \u001b[38;5;241m==\u001b[39m target_labels)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(target_labels))\n\u001b[0;32m---> 22\u001b[0m                 \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m                 total_epochs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/tensorboard/writer.py:393\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m workspace\n\u001b[1;32m    391\u001b[0m     scalar_value \u001b[38;5;241m=\u001b[39m workspace\u001b[38;5;241m.\u001b[39mFetchBlob(scalar_value)\n\u001b[0;32m--> 393\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mscalar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalar_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_style\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(summary, global_step, walltime)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/tensorboard/summary.py:369\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, tensor, collections, new_style, double_precision)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscalar\u001b[39m(name, tensor, collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, new_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, double_precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Output a `Summary` protocol buffer containing a single scalar value.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    The generated Summary has a Tensor.proto containing the input Tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m      ValueError: If tensor has the wrong shape or type.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mmake_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    371\u001b[0m         tensor\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    372\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor should contain one element (0 dimensions). Was given size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# python float is double precision in numpy\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/tensorboard/_convert_np.py:23\u001b[0m, in \u001b[0;36mmake_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([x])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_prepare_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but numpy array, torch tensor, or caffe2 blob name are expected.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/tensorboard/_convert_np.py:30\u001b[0m, in \u001b[0;36m_prepare_pytorch\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_pytorch\u001b[39m(x):\n\u001b[0;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for model, er_f, optim, writer, name, batch_count, epoch_count in tqdm_notebook(models):\n",
    "        model = torch.load(\"88.pth\")\n",
    "        model.eval()\n",
    "        #  = create_model(28, *param)\n",
    "        torch.manual_seed(0)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_count, shuffle=True)\n",
    "        total_epochs = 0\n",
    "        for epoch in tqdm_notebook(range(epoch_count)):\n",
    "            for image, target in tqdm_notebook(data_loader, leave=False):\n",
    "                optim.zero_grad()\n",
    "                outs = model(image)\n",
    "                loss = er_f(outs, target)\n",
    "                loss.backward()\n",
    "                percent: torch.tensor = ((outs.max(1).indices == target.max(1).indices).sum() / len(target))\n",
    "                optim.step()\n",
    "                writer.add_scalar(\"loss\", loss, total_epochs)\n",
    "                writer.add_scalar(\"train_accuracy\", percent, total_epochs)\n",
    "                predicted = model(target_data)\n",
    "                predicted_labels = predicted.max(1).indices\n",
    "                percent: torch.tensor = ((predicted_labels == target_labels).sum() / len(target_labels))\n",
    "                writer.add_scalar(\"test_accuracy\", percent, total_epochs)\n",
    "                total_epochs += 1\n",
    "finally:\n",
    "    write_summary(writer, model)\n",
    "    torch.save(model, f\"model_{name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "data_loader = DataLoader(dataset, batch_size=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "data_loader = DataLoader(dataset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9713ebfafa24afbb3e00cd6dc865e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df44969b978947b49cca4c42b0f6dd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex1um/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55273b2a97f4417b1f4b7f17e446fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edb1040f5ec4ff999208aa83bb96a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex1um/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m         predicted_labels \u001b[38;5;241m=\u001b[39m predicted\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\n\u001b[1;32m     14\u001b[0m         percent: torch\u001b[38;5;241m.\u001b[39mtensor \u001b[38;5;241m=\u001b[39m ((predicted_labels \u001b[38;5;241m==\u001b[39m target_labels)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(target_labels))\n\u001b[0;32m---> 15\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         total_epochs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m write_summary(writer, model)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/tensorboard/writer.py:393\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m workspace\n\u001b[1;32m    391\u001b[0m     scalar_value \u001b[38;5;241m=\u001b[39m workspace\u001b[38;5;241m.\u001b[39mFetchBlob(scalar_value)\n\u001b[0;32m--> 393\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mscalar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalar_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_style\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(summary, global_step, walltime)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/tensorboard/summary.py:369\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, tensor, collections, new_style, double_precision)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscalar\u001b[39m(name, tensor, collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, new_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, double_precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Output a `Summary` protocol buffer containing a single scalar value.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    The generated Summary has a Tensor.proto containing the input Tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m      ValueError: If tensor has the wrong shape or type.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mmake_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    371\u001b[0m         tensor\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    372\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor should contain one element (0 dimensions). Was given size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# python float is double precision in numpy\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/tensorboard/_convert_np.py:23\u001b[0m, in \u001b[0;36mmake_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([x])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_prepare_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but numpy array, torch tensor, or caffe2 blob name are expected.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/tensorboard/_convert_np.py:30\u001b[0m, in \u001b[0;36m_prepare_pytorch\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_pytorch\u001b[39m(x):\n\u001b[0;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for epoch in tqdm_notebook(range(10)):\n",
    "        for image, target in tqdm_notebook(data_loader, leave=False):\n",
    "            optim.zero_grad()\n",
    "            outs = model(image)\n",
    "            loss = er_f(outs, target)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            percent: torch.tensor = ((outs.max(1).indices == target.max(1).indices).sum() / len(target))\n",
    "            writer.add_scalar(\"loss\", loss, total_epochs)\n",
    "            writer.add_scalar(\"train_accuracy\", percent, total_epochs)\n",
    "            predicted = model(target_data)\n",
    "            predicted_labels = predicted.max(1).indices\n",
    "            percent: torch.tensor = ((predicted_labels == target_labels).sum() / len(target_labels))\n",
    "            writer.add_scalar(\"test_accuracy\", percent, total_epochs)\n",
    "            total_epochs += 1\n",
    "    write_summary(writer, model)\n",
    "    torch.save(model, f\"model_{name}.pth\")\n",
    "finally:\n",
    "    write_summary(writer, model)\n",
    "    torch.save(model, f\"model_{name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(model, f\"model_{name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"89.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
